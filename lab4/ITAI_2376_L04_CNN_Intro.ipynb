{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        " Building a CNN for MNIST Handwritten Digit Classification\n",
        "\n",
        "## Introduction\n",
        "\n",
        "Welcome! In this assignment, you will build a Convolutional Neural Network (CNN) to classify handwritten digits from the famous MNIST dataset. This dataset is a classic in the field of computer vision and provides a great starting point for understanding image classification with deep learning.\n",
        "\n",
        "This notebook is structured to guide you step-by-step through the process. You will load the data, preprocess it, define a CNN model, train it, and evaluate its performance.  Throughout the assignment, you will have opportunities to experiment and deepen your understanding of the concepts.\n",
        "\n",
        "Remember to:\n",
        "\n",
        "*   **Read all instructions carefully.**\n",
        "*   **Execute the code cells in order.**\n",
        "*   **Fill in the missing code sections marked as \"Students: Fill in the blanks\".**\n",
        "*   **Answer the reflection questions in the designated Markdown cell.**\n",
        "*   **Experiment and explore!**  Change parameters, layers, and observe the effects.\n",
        "\n",
        "Let's get started and build our MNIST digit classifier!\n",
        "\n",
        "## Section 1: Setting Up - Imports\n",
        "\n",
        "Before we dive into building our CNN, we need to import the necessary libraries.  These libraries provide pre-built tools and functions that will make our work much easier.\n",
        "\n",
        "**Instructions:**\n",
        "\n",
        "1.  **Carefully review the code cell below.** It imports libraries from TensorFlow and Keras, which are powerful frameworks for building and training neural networks.\n",
        "2.  **Execute the code cell by selecting it and pressing [Shift + Enter] (or the \"Run\" button).**\n",
        "3.  **Ensure there are no error messages after running the cell.** If you encounter errors, double-check that you have TensorFlow and Keras installed in your environment."
      ],
      "metadata": {
        "id": "fK46PtzUyabH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: Imports\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "xN_gVhnXyabK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation of Imports:**\n",
        "\n",
        "*   **`tensorflow as tf` and `keras`:** TensorFlow is the main deep learning framework, and Keras is its high-level API that simplifies building and training models. We import TensorFlow as `tf` and Keras directly for easy access to their functionalities.\n",
        "*   **`from tensorflow.keras import layers`:**  This imports the `layers` module from Keras, which provides various layers for building neural networks (like convolutional layers, dense layers, etc.).\n",
        "*   **`from tensorflow.keras.datasets import mnist`:**  This imports the MNIST dataset directly from Keras datasets.  This is very convenient for loading and using the MNIST data.\n",
        "*   **`from tensorflow.keras.utils import to_categorical`:**  This imports the `to_categorical` function, which we will use to perform one-hot encoding of our labels.\n",
        "\n",
        "## Section 2: Data Loading and Preprocessing\n",
        "\n",
        "In this section, we will load the MNIST dataset and prepare it for training our CNN model.  Preprocessing steps are crucial to ensure our data is in the right format for the model to learn effectively.\n",
        "\n",
        "**Instructions:**\n",
        "\n",
        "1.  **Read through the code in the cell below.**  Understand how it loads the MNIST dataset and what preprocessing steps are applied.\n",
        "2.  **Execute the code cell.**\n",
        "3.  **Examine the comments in the code** to understand each preprocessing step in detail."
      ],
      "metadata": {
        "id": "jXAItJ1RyabL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Data Loading and Preprocessing\n",
        "# Load the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_test = x_test.astype(\"float32\") / 255.0\n",
        "\n",
        "# Add a channel dimension (for grayscale images, it's 1)\n",
        "x_train = x_train.reshape(-1, 28, 28, 1)\n",
        "x_test = x_test.reshape(-1, 28, 28, 1)\n",
        "\n",
        "# One-hot encode the labels\n",
        "num_classes = 10\n",
        "y_train = to_categorical(y_train, num_classes)\n",
        "y_test = to_categorical(y_test, num_classes)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "OCi441G0yabL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation of Data Preprocessing:**\n",
        "\n",
        "*   **Loading the MNIST dataset:** `mnist.load_data()` loads the MNIST dataset, which is already split into training and testing sets (`(x_train, y_train), (x_test, y_test)`). `x_train` and `x_test` contain the images (pixel data), and `y_train` and `y_test` contain the corresponding labels (digits 0-9).\n",
        "*   **Normalization:** `x_train = x_train.astype(\"float32\") / 255.0` and `x_test = x_test.astype(\"float32\") / 255.0` normalize the pixel values.  Pixel values in images are typically in the range 0-255. Dividing by 255 scales them to the range 0-1. This normalization helps the neural network train faster and more effectively.\n",
        "*   **Adding Channel Dimension:** `x_train = x_train.reshape(-1, 28, 28, 1)` and `x_test = x_test.reshape(-1, 28, 28, 1)` reshape the data to add a channel dimension.  Even though MNIST images are grayscale (single channel), CNNs in Keras expect input data to have a channel dimension.  We reshape from `(number_of_images, 28, 28)` to `(number_of_images, 28, 28, 1)`. The `-1` in `reshape` means \"infer the dimension based on the size of the array.\"\n",
        "*   **One-Hot Encoding:** `y_train = to_categorical(y_train, num_classes)` and `y_test = to_categorical(y_test, num_classes)` perform one-hot encoding on the labels.  Instead of representing the digit '3' as a single number, one-hot encoding converts it into a vector `[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]`, where the 4th position (index 3) is 'hot' (value 1), and all other positions are 'cold' (value 0). This is a standard way to represent categorical labels for neural networks in multi-class classification problems. `num_classes = 10` specifies that we have 10 classes (digits 0-9).\n",
        "\n",
        "## Section 3: Model Definition - Building the CNN\n",
        "\n",
        "Now we will define the architecture of our Convolutional Neural Network (CNN).  You will be building a sequential model using Keras layers.\n",
        "\n",
        "**Instructions:**\n",
        "\n",
        "1.  **Carefully examine the code in the cell below.** Notice the structure of the `keras.Sequential` model.\n",
        "2.  **Fill in the missing parts** marked with `# Students: Fill in the blanks` to complete the model definition.\n",
        "3.  **Experiment!** You are encouraged to try different configurations for the layers, such as changing the number of filters in the convolutional layers, or adding more layers."
      ],
      "metadata": {
        "id": "UNkWB4hvyabM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Model Definition\n",
        "# Build the CNN model.  Students: Fill in the missing parts!\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(28, 28, 1)),  # Input layer\n",
        "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"), # Convolutional layer 1\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)), # Max pooling layer 1\n",
        "        # Students: Add another Conv2D layer here.  Experiment with the number of filters!\n",
        "        # layers.Conv2D(____, kernel_size=(____, ____), activation=\"____\"),  # Convolutional layer 2\n",
        "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"), # Convolutional layer 2\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)), # Max pooling layer 2\n",
        "        # Students: Add another MaxPooling2D layer here if needed.\n",
        "        # layers.MaxPooling2D(pool_size=(____, ____)),  # Max pooling layer 2\n",
        "        layers.Flatten(),  # Flatten layer\n",
        "        layers.Dropout(0.5),  # Dropout layer\n",
        "        layers.Dense(num_classes, activation=\"softmax\"),  # Output layer\n",
        "    ]\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "FFOe2fviyabM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation of Layers:**\n",
        "\n",
        "*   **`keras.Input(shape=(28, 28, 1))`:** This is the input layer of our model. It specifies the shape of the input images, which are 28x28 pixels with 1 channel (grayscale).\n",
        "*   **`layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\")`:** This is a 2D Convolutional layer.\n",
        "    *   `32`: This is the number of filters (also called kernels). Each filter learns to detect specific features in the input image.\n",
        "    *   `kernel_size=(3, 3)`: This defines the size of the convolutional filter as 3x3 pixels.\n",
        "    *   `activation=\"relu\"`:  ReLU (Rectified Linear Unit) is the activation function. It introduces non-linearity into the model, allowing it to learn complex patterns.\n",
        "*   **`layers.MaxPooling2D(pool_size=(2, 2))`:** This is a Max Pooling layer.\n",
        "    *   `pool_size=(2, 2)`:  It reduces the spatial dimensions of the feature maps by taking the maximum value within each 2x2 window. This helps to reduce the number of parameters, control overfitting, and make the model more robust to small shifts and distortions in the input.\n",
        "*   **`layers.Flatten()`:** This layer flattens the 2D feature maps from the convolutional and pooling layers into a 1D vector. This is necessary to connect the convolutional part of the network to the fully connected (Dense) layers.\n",
        "*   **`layers.Dropout(0.5)`:** This is a Dropout layer.\n",
        "    *   `0.5`: This sets the dropout rate to 50%. During training, this layer randomly sets 50% of the input units to 0 at each update. This is a regularization technique that helps to prevent overfitting.\n",
        "*   **`layers.Dense(num_classes, activation=\"softmax\")`:** This is the output Dense (fully connected) layer.\n",
        "    *   `num_classes`:  This is set to 10 because we have 10 classes (digits 0-9).\n",
        "    *   `activation=\"softmax\"`: Softmax activation ensures that the output values are probabilities, and they sum up to 1 across all classes.  The output will be a vector of 10 probabilities, where each probability represents the model's confidence that the input image belongs to that specific digit class.\n",
        "\n",
        "## Section 4: Model Compilation - Choosing Loss and Optimizer\n",
        "\n",
        "Before we can train our model, we need to compile it.  Compilation involves choosing an optimizer, a loss function, and metrics to evaluate the model's performance.\n",
        "\n",
        "**Instructions:**\n",
        "\n",
        "1.  **Examine the code cell below.** You need to fill in the blanks for the `loss` and `optimizer` parameters in `model.compile()`.\n",
        "2.  **Choose an appropriate loss function and optimizer** for this multi-class classification problem.\n",
        "3.  **In the Markdown cell after the code, explain your choices.** Why are these choices suitable for this task?"
      ],
      "metadata": {
        "id": "-x0iiCewyabM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: Model Compilation\n",
        "# Students: Choose an appropriate loss function and optimizer.  Why did you choose these?\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]) #Students: Fill in the blanks"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "YVr-ooXfyabM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation of Choices (To be filled by students in the reflection section):**\n",
        "\n",
        "*   **Loss Function:** You need to choose a loss function that is appropriate for multi-class classification. Think about what kind of error we are trying to minimize when classifying digits into 10 categories.\n",
        "*   **Optimizer:** You need to choose an optimizer that will efficiently update the model's weights to minimize the loss function.  Consider common optimizers used in deep learning.\n",
        "*   **Metrics:** We are using \"accuracy\" as a metric to evaluate the model's performance. Accuracy is a common metric for classification tasks, representing the percentage of correctly classified images.\n",
        "\n",
        "## Section 5: Model Training - Fitting the Model to the Data\n",
        "\n",
        "Now it's time to train our CNN model using the training data. Training involves feeding the training data to the model and adjusting its weights to minimize the loss function.\n",
        "\n",
        "**Instructions:**\n",
        "\n",
        "1.  **Examine the code cell below.** You need to fill in the blanks for `batch_size` and `epochs` in `model.fit()`.\n",
        "2.  **Choose appropriate values for `batch_size` and `epochs`.**\n",
        "3.  **Run the code cell to start training.** Observe the training progress, especially the loss and accuracy on both the training and validation sets.\n",
        "4.  **Experiment!** Change the `batch_size` and `epochs` and see how it affects the training process and the final performance."
      ],
      "metadata": {
        "id": "2R7iy69RyabN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: Model Training\n",
        "# Students: Adjust the batch size and number of epochs.  What happens if you change them?\n",
        "model.fit(x_train, y_train, batch_size=128, epochs=15, validation_split=0.1) #Students: Fill in the blanks"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "UtpZIbTHyabN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation of Training Parameters:**\n",
        "\n",
        "*   **`batch_size`:** This determines the number of training samples processed in each mini-batch during training. A larger batch size can speed up training but might require more memory. A smaller batch size can lead to more noisy updates but might generalize better.\n",
        "*   **`epochs`:**  One epoch represents one complete pass through the entire training dataset.  More epochs can potentially lead to better training but also increase the risk of overfitting, where the model learns the training data too well and performs poorly on unseen data.\n",
        "*   **`validation_split=0.1`:**  This reserves 10% of the training data as a validation set. During training, the model's performance is evaluated on this validation set after each epoch. This helps to monitor for overfitting and tune hyperparameters.\n",
        "\n",
        "## Section 6: Model Evaluation - Assessing Performance on Test Data\n",
        "\n",
        "After training, we need to evaluate our model's performance on the test dataset.  This gives us an estimate of how well the model generalizes to unseen data.\n",
        "\n",
        "**Instructions:**\n",
        "\n",
        "1.  **Run the code cell below.**\n",
        "2.  **Observe the output.**  It will print the test loss and test accuracy.\n",
        "3.  **Think about the results.** Is the test accuracy satisfactory?  How does it compare to the training and validation accuracy you observed during training?"
      ],
      "metadata": {
        "id": "6FW7k1KMyabN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: Model Evaluation\n",
        "loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(f\"Test loss: {loss:.4f}\")\n",
        "print(f\"Test accuracy: {accuracy:.4f}\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "f3KehXAlyabO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 7: Reflection and Answers to Questions\n",
        "This is an important section! Take some time to reflect on what you have learned and answer the following questions in detail. Your thoughtful answers will demonstrate your understanding of the concepts covered in this assignment.\n",
        "\n",
        "**Reflection Questions:**\n",
        "\n",
        "1.  **Conv2D Layer:** What is the role of the Conv2D layer? How do the `kernel_size` and the number of filters affect the learning process? *Hint: Experiment by changing these values in Cell 3.*\n",
        "\n",
        "2.  **MaxPooling2D Layer:** What is the purpose of the MaxPooling2D layer? How does it contribute to the model's performance?  *Hint:  Try removing or adding a MaxPooling2D layer and see what happens.*\n",
        "\n",
        "3.  **One-Hot Encoding:** Why do we use one-hot encoding for the labels?\n",
        "\n",
        "4.  **Flatten Layer:** Why do we need the Flatten layer before the Dense layer?\n",
        "\n",
        "5.  **Optimizer and Loss Function:** What optimizer and loss function did you choose in Cell 4? Explain your choices.  Why is categorical cross-entropy a suitable loss function for this task?  Why is Adam a good choice of optimiser?\n",
        "\n",
        "6.  **Batch Size and Epochs:** How did you choose the batch size and number of epochs in Cell 5? What are the effects of changing these parameters?  *Hint:  Experiment!*\n",
        "\n",
        "7.  **Dropout:**  Why is the Dropout layer included in the model?\n",
        "\n",
        "8.  **Model Architecture:**  Describe the overall architecture of your CNN. How many convolutional layers did you use?  How many max pooling layers?  What is the final dense layer doing?\n",
        "\n",
        "9.  **Performance:** What accuracy did you achieve on the test set?  Are you happy with the result? Why or why not?  If you're not happy, what could you try to improve the performance?\n",
        "\n",
        "**Tips and Explanations:**\n",
        "\n",
        "*   **Normalization:**  Dividing the pixel values by 255 normalizes them to the range [0, 1]. This is important for training neural networks.\n",
        "\n",
        "*   **Reshaping:**  The `reshape` operation adds a channel dimension to the images.  For grayscale images, the channel dimension is 1.\n",
        "\n",
        "*   **One-Hot Encoding:** `to_categorical` converts the class labels (0-9) into one-hot encoded vectors.\n",
        "\n",
        "*   **Conv2D Parameters:** The `kernel_size` determines the size of the convolutional filter (e.g., 3x3). The number of filters determines how many different features are learned.\n",
        "\n",
        "*   **MaxPooling2D Parameters:** The `pool_size` determines the size of the pooling window (e.g., 2x2).\n",
        "\n",
        "*   **Optimizer:** The optimizer is the algorithm used to update the model's weights during training.\n",
        "\n",
        "*   **Loss Function:** The loss function measures the error between the model's predictions and the true labels.\n",
        "\n",
        "*   **Batch Size:** The batch size is the number of samples processed in each training iteration.\n",
        "\n",
        "*   **Epochs:** An epoch is one complete pass through the entire training dataset.\n",
        "\n",
        "*   **Dropout:** Dropout is a regularization technique that helps prevent overfitting.\n",
        "\n",
        "Remember to run each cell to see its output.  Experiment with the code and try to understand how different parameters affect the model's performance.  Good luck!\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "VL_6FT9K5bBr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion and Submission\n",
        " Congratulations on completing this notebook assignment! You have successfully built and trained a Convolutional Neural\n",
        " Network to classify handwritten digits from the MNIST dataset. You've explored key concepts like convolutional layers, pooling layers, activation functions, optimizers, loss functions, and training procedures. To further solidify your understanding, consider the following:\n",
        "*   **Review your notebook:** Go back through each section, reread the explanations, and make sure you understand the code and the concepts.\n",
        "*   **Experiment further:** Try different CNN architectures, add more layers, change hyperparameters, and see how it affects the performance. Explore other optimizers or loss functions.\n",
        "*   **Reflect on your learning:**  Think about the challenges you faced and how you overcame them. What were the most important takeaways for you from this assignment?\n",
        "\n",
        "**Submission Instructions**\n",
        "\n",
        "To submit your assignment:\n",
        "\n",
        "1.  **Save your notebook:** Ensure all your work, including code cells, outputs, and answers to reflection questions, is saved in the notebook.\n",
        "2.  **Print the notebook as a `.pdf` file** and submit it to Canvas.\n",
        "\n",
        "**Deadline:** February, 12th"
      ],
      "metadata": {
        "id": "e9_VbuuK6MFg"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}